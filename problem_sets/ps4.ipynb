{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93657954-d884-4662-8d87-88c0d612d8c9",
    "source-id": "21b54a7f-a97a-4585-9755-d27857445b64"
   },
   "source": [
    "# SI 106 Problem Set 4\n",
    "\n",
    "Primary Topics:\n",
    "- Files\n",
    "- Dictionaries\n",
    "- Dictionary Accumulation\n",
    "\n",
    "Lookahead Topics:\n",
    "- Defining Functions\n",
    "- Tuple Packing and Unpacking\n",
    "- Advanced Functions (keyword & optional parameters, lambda expressions)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "764ad8b3-eb2b-4ba2-9e0e-e63998ee74a8",
    "source-id": "6ce75932-b28e-4232-9113-4a3e5799ac73"
   },
   "source": [
    "---\n",
    "## Problem 1\n",
    "\n",
    "We have provided a list of tuples called `state_capitals`. The first item in every tuple is the name of a US state and the second item in that tuple is the capital of that state. Write code that converts this data structure into a dictionary where the keys are state names and the values are state capitals. Assign the result to the variables `capitals_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eec155f6-949b-45ae-b2ca-55ced97d12f5",
    "source-id": "ab043d37-ecce-4b41-bac9-1bb6ca38e2d8"
   },
   "outputs": [],
   "source": [
    "state_capitals = [ ('Michigan', 'Lansing'), ('Massachusetts', 'Boston'), ('Pennsylvania', 'Harrisburg'), ('New York', 'Albany')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "be7b5af0-580e-4bbe-8ad1-d306e57ba9ff",
    "source-id": "c6731e7e-c8a9-495a-9f09-50c392c1bd8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Michigan': 'Lansing', 'Massachusetts': 'Boston', 'Pennsylvania': 'Harrisburg', 'New York': 'Albany'}\n"
     ]
    }
   ],
   "source": [
    "capitals_dict = {}\n",
    "\n",
    "for tup in state_capitals:\n",
    "    capitals_dict[tup[0]] = tup[1]\n",
    "\n",
    "print(capitals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1954af54-4e8f-4260-8577-3916f86df0dc",
    "source-id": "ad034198-59fb-4708-851e-1b3a3097aec8"
   },
   "source": [
    "### Problem 1 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "72e83918-84cc-4d31-9341-13145a9a2ad1",
    "source-id": "ace887df-2c9d-4cef-a08e-b37b45e3029d"
   },
   "outputs": [],
   "source": [
    "assert capitals_dict == {'Michigan': 'Lansing', 'Massachusetts': 'Boston', 'Pennsylvania': 'Harrisburg', 'New York': 'Albany' }, \"Testing that the capitals_dict dictionary has the correct key-value pairs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4763c35-451f-4a1c-a310-d6fde58f6130",
    "source-id": "7fce178e-8e16-4171-9ab8-bd4ca2aa3048"
   },
   "source": [
    "---\n",
    "## Problem 2\n",
    "\n",
    "The dictionary `calories` contains calorie totals for different kinds of food. The list `lunch` is a list of food items in a meal. Write code that computes the total number of calories in `lunch` by adding up the calories associated with every item in the list. Put the result in the variable `lunch_calories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "efb9f282-4971-4523-8604-61ae32065d35",
    "source-id": "14fc5d05-c5d8-44e9-92aa-19d9cd5b2716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n"
     ]
    }
   ],
   "source": [
    "calories = {\n",
    "    'pizza slice': 285,\n",
    "    'french fries': 365,\n",
    "    'ice cream': 137,\n",
    "    'pancake': 64,\n",
    "    'orange': 45,\n",
    "    'cupcake': 131\n",
    "}\n",
    "\n",
    "lunch = ['pizza slice', 'orange', 'cupcake', 'cupcake']\n",
    "lunch_calories = 0\n",
    "\n",
    "for food_itm in lunch:\n",
    "    if food_itm in calories.keys():\n",
    "        lunch_calories += calories[food_itm]\n",
    "\n",
    "print(lunch_calories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0796f3a8-890b-4755-97d2-a7ab29794bc5",
    "source-id": "fd81a69d-06b3-469b-bd39-0f94d954d8e2"
   },
   "source": [
    "### Problem 2 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "64afd9a6-6ab1-4b78-889a-155093bcf147",
    "source-id": "b2994646-c485-442d-96d1-7a5e880c77bd"
   },
   "outputs": [],
   "source": [
    "assert lunch_calories == 285+45+131*2, \"Testing that the lunch_calories has the correct value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31b10b03-40b2-4a99-8707-e38025073499",
    "source-id": "479a9fa3-d51c-4319-9bc6-0f66c2069a02"
   },
   "source": [
    "---\n",
    "## Problem 3\n",
    "\n",
    "The dictionary `snowfalls` maps keys (which represent a given month) to values that represent the amount of snowfall (in inches) for every time it snowed that month. Write code that creates a new dictionary named `month_total_snowfall` where the keys are months and the values are floats that represent the **total** snowfall for that month (the sum of the values in `snowfalls` for that month).\n",
    "\n",
    "Then, create a new float called `snowfall_all_months` whoes value is the total snowfall for all months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7c9e2c87-709b-4173-8c18-2f0f2fdcf5c6",
    "source-id": "f193dbf6-dfe5-40e0-bf73-dd559da5a7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'December': 0.2, 'January': 9.0, 'February': 14.5, 'March': 8.5, 'April': 0.2}\n",
      "32.400000000000006\n"
     ]
    }
   ],
   "source": [
    "snowfalls = {\n",
    "    'December': [0.2],\n",
    "    'January': [1.5, 3, 2, 2.5],\n",
    "    'February': [7, 2.3, 1.2, 4],\n",
    "    'March': [1.5, 3, 4],\n",
    "    'April': [0.2],\n",
    "}\n",
    "\n",
    "month_total_snowfall = {}\n",
    "\n",
    "for month, snow in snowfalls.items():\n",
    "    month_total_snowfall[month] = sum(snow)\n",
    "    \n",
    "print(month_total_snowfall)\n",
    "\n",
    "snowfall_all_months = sum(month_total_snowfall.values())\n",
    "\n",
    "print(snowfall_all_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ce71a41-a129-419d-b319-2aefcafd8918",
    "source-id": "7435f0bc-c1d8-480f-ad7c-0cff46495b1b"
   },
   "source": [
    "### Problem 3 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cd016fa3-b148-4277-9f8c-d2f7f1fd7af8",
    "source-id": "0c935d2c-c026-4b4b-87c9-c866f79fbe48"
   },
   "outputs": [],
   "source": [
    "assert month_total_snowfall == {'December': 0.2, 'January': 9.0, 'February': 14.5, 'March': 8.5, 'April': 0.2}, \"Testing that month_total_snowfall has the correct keys and values\"\n",
    "assert snowfall_all_months > 32.39 and snowfall_all_months < 32.41, \"Testing that snowfall_all_months has the correct value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de380826-344a-4469-afe5-6ad9a053a6ff",
    "source-id": "ee206ab0-b256-4a4f-9483-17b8af6ed68b"
   },
   "source": [
    "---\n",
    "## Problem 4\n",
    "\n",
    "The dictionary `umSchools` maps the names of schools at Michigan to the year they were founded.\n",
    "Write code to add the name of every school that was founded in the 20th century (after 1900) into a list `newer_schools`.\n",
    "\n",
    "Hard-coded answers will receive no credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "685c0752-b286-418c-a82b-36e2b395da81",
    "source-id": "f5a6a0fb-d1f7-440f-bfe7-8f3384d71ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A. Alfred Taubman College of Architecture & Urban Planning': 1906, 'Gerald R. Ford School of Public Policy': 1914, 'Horace H. Rackham School of Graduate Studies': 1912, 'Penny W. Stamps School of Art & Design': 1974, 'School of Education': 1921, 'School of Information': 1996, 'School of Kinesiology': 1984, 'School of Natural Resources & Environment': 1927, 'School of Public Health': 1941, 'School of Social Work': 1951, 'Stephen M. Ross School of Business': 1924}\n"
     ]
    }
   ],
   "source": [
    "umSchools = {\n",
    "    \"A. Alfred Taubman College of Architecture & Urban Planning\": 1906,\n",
    "    \"College of Engineering\": 1854,\n",
    "    \"College of Literature, Science, and the Arts\": 1841,\n",
    "    \"Gerald R. Ford School of Public Policy\": 1914,\n",
    "    \"Horace H. Rackham School of Graduate Studies\": 1912,\n",
    "    \"Penny W. Stamps School of Art & Design\": 1974,\n",
    "    \"School of Dentistry\": 1875,\n",
    "    \"School of Education\": 1921,\n",
    "    \"School of Information\": 1996,\n",
    "    \"School of Kinesiology\": 1984,\n",
    "    \"School of Law\": 1859,\n",
    "    \"School of Medicine\": 1850,\n",
    "    \"School of Music, Theatre & Dance\": 1880,\n",
    "    \"School of Natural Resources & Environment\": 1927,\n",
    "    \"School of Nursing\": 1893,\n",
    "    \"School of Pharmacy\": 1876,\n",
    "    \"School of Public Health\": 1941,\n",
    "    \"School of Social Work\": 1951,\n",
    "    \"Stephen M. Ross School of Business\": 1924\n",
    "}\n",
    "\n",
    "newer_schools = {}\n",
    "\n",
    "for name, year in umSchools.items():\n",
    "    if year > 1900 and year < 2001:\n",
    "        newer_schools[name] = year\n",
    "\n",
    "print(newer_schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5c74b16-7c99-43c9-92af-3810c9cb7783",
    "source-id": "bd12fe4d-4bcc-473b-aa31-5c332bc14f98"
   },
   "source": [
    "### Problem 4 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6374cb58-716d-4506-93ab-180fc5ce1049",
    "source-id": "858cd98e-6a50-4887-9f86-56e3f2efae3d"
   },
   "outputs": [],
   "source": [
    "assert sorted(newer_schools) == sorted(['A. Alfred Taubman College of Architecture & Urban Planning',\n",
    " 'Gerald R. Ford School of Public Policy',\n",
    " 'Horace H. Rackham School of Graduate Studies',\n",
    " 'Penny W. Stamps School of Art & Design',\n",
    " 'School of Education',\n",
    " 'School of Information',\n",
    " 'School of Kinesiology',\n",
    " 'School of Natural Resources & Environment',\n",
    " 'School of Public Health',\n",
    " 'School of Social Work',\n",
    " 'Stephen M. Ross School of Business']), \"Testing that newer_schools has been set to the correct value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3330ef6-912d-438f-9b87-ebb368ac9561",
    "source-id": "3628ae71-b735-432a-83a3-ee7d39d0516d"
   },
   "source": [
    "---\n",
    "## Problem 5\n",
    "The dictionary `umSchools` maps the names of schools at Michigan to the year they were founded.\n",
    "Write code that determines which school is the oldest and store the name of the school into the variable `oldest_school`.\n",
    "Hard-coded answers will receive no credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2c121672-e978-4fed-b6bc-a852668c3736",
    "source-id": "cf844e32-a47e-4739-a1a2-ca3d764dc1e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "College of Literature, Science, and the Arts\n"
     ]
    }
   ],
   "source": [
    "umSchools = {\n",
    "  \"A. Alfred Taubman College of Architecture & Urban Planning\": 1906,\n",
    "  \"College of Engineering\": 1854,\n",
    "  \"College of Literature, Science, and the Arts\": 1841,\n",
    "  \"Gerald R. Ford School of Public Policy\": 1914,\n",
    "  \"Horace H. Rackham School of Graduate Studies\": 1912,\n",
    "  \"Penny W. Stamps School of Art & Design\": 1974,\n",
    "  \"School of Dentistry\": 1875,\n",
    "  \"School of Education\": 1921,\n",
    "  \"School of Information\": 1996,\n",
    "  \"School of Kinesiology\": 1984,\n",
    "  \"School of Law\": 1859,\n",
    "  \"School of Medicine\": 1850,\n",
    "  \"School of Music, Theatre & Dance\": 1880,\n",
    "  \"School of Natural Resources & Environment\": 1927,\n",
    "  \"School of Nursing\": 1893,\n",
    "  \"School of Pharmacy\": 1876,\n",
    "  \"School of Public Health\": 1941,\n",
    "  \"School of Social Work\": 1951,\n",
    "  \"Stephen M. Ross School of Business\": 1924\n",
    "}\n",
    "\n",
    "keys = list(umSchools.keys())\n",
    "oldest_school = keys[0]\n",
    "\n",
    "for key in keys:\n",
    "    if umSchools[oldest_school] > umSchools[key]:\n",
    "        oldest_school = key\n",
    "\n",
    "print(oldest_school)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "910b1068-a958-4716-88f6-2ca89bdf1505",
    "source-id": "09e430c4-d6f3-4f76-aeb8-387fdb05278f"
   },
   "source": [
    "### Problem 5 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "323af2c7-cda0-472b-b769-bbac82f7249f",
    "source-id": "36c198f8-67bd-4425-9b6a-fd952d973893"
   },
   "outputs": [],
   "source": [
    "assert oldest_school == 'College of Literature, Science, and the Arts', \"Testing that oldest_school has been correctly set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5afbe3c-85d2-413f-998b-7c4f7c09bc4d",
    "source-id": "a428380d-ba3a-4c2d-8126-f424b3a9720b"
   },
   "source": [
    "---\n",
    "\n",
    "## Problem 6\n",
    "`rhyme` is a string. Write code that assigns `most_frequent_character` to the most frequent character in `rhyme`. Note: your code should be case-sensitive (`\"a\"` is different than `\"A\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4d85723e-af85-4874-b2d9-5df4b938d039",
    "source-id": "3a606445-bb8c-43d6-b7a4-86a9b7e2b7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n"
     ]
    }
   ],
   "source": [
    "rhyme = \"\"\"peter piper picked a peck of pickled peppers.\n",
    "a peck of pickled peppers peter piper picked.\n",
    "if peter piper picked a peck of pickled peppers,\n",
    "where's the peck of pickled peppers peter piper picked?\"\"\"\n",
    "\n",
    "dict1 = {}\n",
    "\n",
    "for achar in rhyme:\n",
    "    dict1[achar] = dict1.get(achar, 0) + 1\n",
    "\n",
    "keys = list(dict1.keys())\n",
    "most_frequent_character = keys[0]\n",
    "\n",
    "for key in keys:\n",
    "    if dict1[most_frequent_character] < dict1[key]:\n",
    "        most_frequent_character = key\n",
    "        \n",
    "print(most_frequent_character)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5311fdd1-ac86-4eb8-8349-2261fe0978a7",
    "source-id": "f7404208-e3e5-43aa-8137-95d63b6310c9"
   },
   "outputs": [],
   "source": [
    "assert most_frequent_character == 'p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "528d1aff-4f62-445a-9af0-02bef8304d7a",
    "source-id": "847b4df8-aab4-45f5-b681-f21c380fcc66"
   },
   "source": [
    "---\n",
    "\n",
    "## Problem 7\n",
    "\n",
    "The file `three_musketeers.txt` contains the contents of the English translation of \"The Three Musketeers\" by Alexandre Dumas. Write code to assign `most_frequent_word` to be the most frequent word in the book. Your code should be case-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2b15de6a-94e5-413f-8909-ad16c1431aab",
    "source-id": "86f59bc2-7444-4856-9834-a1d53656fed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "with open('three_musketeers.txt','r',encoding=\"utf-8\") as file:\n",
    "    wrds_count = {}\n",
    "\n",
    "    for word in file.read().split():\n",
    "        wrds_count[word] = wrds_count.get(word, 0) + 1\n",
    "\n",
    "    keys = list(wrds_count.keys())\n",
    "    most_frequent_word = keys[0]\n",
    "\n",
    "    for key in keys:\n",
    "        if wrds_count[most_frequent_word] < wrds_count[key]:\n",
    "            most_frequent_word = key\n",
    "        \n",
    "    print(most_frequent_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e5097b02-2a55-4eda-9cc2-bda551843388",
    "source-id": "1a4e3ba1-b93f-4309-813a-67f6f197d5f6"
   },
   "outputs": [],
   "source": [
    "assert most_frequent_word == 'the'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52fd334a-c16f-4ecb-9896-5085b7b67385",
    "source-id": "f48b61a1-f367-4cee-a4e6-1a5d684ad2d9"
   },
   "source": [
    "---\n",
    "## Problem 8\n",
    "There is a CSV-formatted file called `olympics2.csv` write code that will create a list of **unique** olympians (no name should appear more than once). Put your result in the variable `olympians`.\n",
    "\n",
    "*Note 1: your code must ignore the header row*\n",
    "*Note 2: you may want to start by writing code that read and prints out the file content*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ff5e9508-fe26-4504-92a8-36a166bbcc39",
    "source-id": "2ddd887f-9fc8-4017-ae5d-bf60ccc2615b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Dijiang', 'A Lamusi', 'Gunnar Nielsen Aaby', 'Edgar Lindenau Aabye', 'Christine Jacoba Aaftink', 'Per Knut Aaland', 'John Aalberg', '\"Cornelia \"\"Cor\"\" Aalten (-Strannood)\"', 'Antti Sami Aalto', '\"Einar Ferdinand \"\"Einari\"\" Aalto\"', 'Jorma Ilmari Aalto', 'Jyri Tapani Aalto', 'Minna Maarit Aalto', 'Pirjo Hannele Aalto (Mattila-)', 'Arvo Ossian Aaltonen', 'Juhamatti Tapio Aaltonen', 'Paavo Johannes Aaltonen', 'Timo Antero Aaltonen', 'Win Valdemar Aaltonen']\n"
     ]
    }
   ],
   "source": [
    "with open('olympics2.csv','r') as file:\n",
    "    lines = file.readlines()\n",
    "    olympians = []\n",
    "    \n",
    "    for row in lines[1:]:\n",
    "        accomp = row.strip().split(',')\n",
    "        if accomp[0] not in olympians:\n",
    "            olympians.append(accomp[0])\n",
    "            \n",
    "    print(olympians)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "535c63fd-ef3f-4365-84c5-165bd7ba3409",
    "source-id": "22c0d4c7-3858-4f3b-86c0-8c7aacd42bf0"
   },
   "source": [
    "### Problem 8 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6e937ee8-7489-4fa9-9bbe-c9b1b820a9dd",
    "source-id": "a3838250-ff54-4ef0-b7ef-a962e6043dd6"
   },
   "outputs": [],
   "source": [
    "correctOlympians = ['A Dijiang', 'A Lamusi', 'Gunnar Nielsen Aaby', 'Edgar Lindenau Aabye', 'Christine Jacoba Aaftink', 'Per Knut Aaland', 'John Aalberg', '\"Cornelia \"\"Cor\"\" Aalten (-Strannood)\"', 'Antti Sami Aalto', '\"Einar Ferdinand \"\"Einari\"\" Aalto\"', 'Jorma Ilmari Aalto', 'Jyri Tapani Aalto', 'Minna Maarit Aalto', 'Pirjo Hannele Aalto (Mattila-)', 'Arvo Ossian Aaltonen', 'Juhamatti Tapio Aaltonen', 'Paavo Johannes Aaltonen', 'Timo Antero Aaltonen', 'Win Valdemar Aaltonen']\n",
    "assert sorted(olympians) == sorted(correctOlympians), \"Checking that olympians has the correct value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "139f2e4c-b465-4fec-8177-2f01237956a1",
    "source-id": "ba499b5e-ce2c-4914-98f3-8b4816db9f77"
   },
   "source": [
    "---\n",
    "## Problem 9\n",
    "\n",
    "There is a CSV-formatted file called ``olympics2.csv``. Write code that creates a dictionary named ``country_olympians`` where the keys are country names and the values are lists of **unique** olympians from that country (no olympian's name should appear more than once for a given country)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "005a7a2c-0966-4bf6-958b-b2b5e7ab9989",
    "scrolled": true,
    "source-id": "b8913b18-2194-47f3-b338-d0e922789f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'China': ['A Dijiang', 'A Lamusi'], 'Denmark': ['Gunnar Nielsen Aaby'], 'Sweden': ['Edgar Lindenau Aabye'], 'Netherlands': ['Christine Jacoba Aaftink', '\"Cornelia \"\"Cor\"\" Aalten (-Strannood)\"'], 'United States': ['Per Knut Aaland', 'John Aalberg'], 'Finland': ['Antti Sami Aalto', '\"Einar Ferdinand \"\"Einari\"\" Aalto\"', 'Jorma Ilmari Aalto', 'Jyri Tapani Aalto', 'Minna Maarit Aalto', 'Pirjo Hannele Aalto (Mattila-)', 'Arvo Ossian Aaltonen', 'Juhamatti Tapio Aaltonen', 'Paavo Johannes Aaltonen', 'Timo Antero Aaltonen', 'Win Valdemar Aaltonen']}\n"
     ]
    }
   ],
   "source": [
    "with open('olympics2.csv','r') as file:\n",
    "    lines = file.readlines()\n",
    "    country_olympians = {}\n",
    "    \n",
    "    for row in lines[1:]:\n",
    "        accomp = row.strip().split(',')\n",
    "        country = accomp[3]\n",
    "        name = accomp[0]\n",
    "        if country not in country_olympians:\n",
    "            country_olympians[country] = []\n",
    "        if name not in country_olympians[country]:\n",
    "            country_olympians[country] = country_olympians[country] + [name]\n",
    "            \n",
    "    print(country_olympians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8524e161-ac89-452e-9098-1b97a5f2accd",
    "source-id": "ca49da2b-e533-451e-b65b-f1690539b645"
   },
   "source": [
    "### Problem 9 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e7e3c1f8-1f51-4b24-8d54-1ec0b1ec2414",
    "source-id": "b5346ca2-3057-4d2e-a84b-bf9531d47b27"
   },
   "outputs": [],
   "source": [
    "correctCountryOlympians = {'China': ['A Dijiang', 'A Lamusi'], 'Denmark': ['Gunnar Nielsen Aaby'], 'Sweden': ['Edgar Lindenau Aabye'], 'Netherlands': ['Christine Jacoba Aaftink', '\"Cornelia \"\"Cor\"\" Aalten (-Strannood)\"'], 'United States': ['Per Knut Aaland', 'John Aalberg'], 'Finland': ['Antti Sami Aalto', '\"Einar Ferdinand \"\"Einari\"\" Aalto\"', 'Jorma Ilmari Aalto', 'Jyri Tapani Aalto', 'Minna Maarit Aalto', 'Pirjo Hannele Aalto (Mattila-)', 'Arvo Ossian Aaltonen', 'Juhamatti Tapio Aaltonen', 'Paavo Johannes Aaltonen', 'Timo Antero Aaltonen', 'Win Valdemar Aaltonen']}\n",
    "\n",
    "assert sorted(country_olympians['China']) == sorted(correctCountryOlympians['China']), \"Testing country_olympians['China']\"\n",
    "assert sorted(country_olympians['Netherlands']) == sorted(correctCountryOlympians['Netherlands']), \"Testing country_olympians['Netherlands']\"\n",
    "assert sorted(country_olympians['United States']) == sorted(correctCountryOlympians['United States']), \"Testing country_olympians['United States']\"\n",
    "assert sorted(country_olympians['Denmark']) == sorted(correctCountryOlympians['Denmark']), \"Testing country_olympians['Denmark']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a49154fb-6c5b-4274-b301-49315c9201a6",
    "source-id": "4b1dd19c-52fe-4b47-a8be-933e4513ec7a"
   },
   "source": [
    "---\n",
    "## Problem 10\n",
    "\n",
    "Write the data in variable ``artist_songs`` into a csv file, ``'songs.txt'``, where the first column is singer name and second column is a song name. Each line should have a singer and a song name. Use ``\"Name\"`` and ``\"Song``\" as headers. Do not include double quotation marks (``\"``) in your CSV but you should include apostrophes where necessary (for example, for the song ``\"We Don't Talk Anymore\"``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "e434e07e-829d-4f6e-82ab-0fd0ff01f86b",
    "source-id": "c8cd0fd2-0b6a-4090-811f-dae0011d5ee7"
   },
   "outputs": [],
   "source": [
    "artist_songs = {\n",
    "    'Taylor Swift': ['Love Story', 'You need to Calm Down'],\n",
    "    'Charlie Puth': ['Attention', \"We Don't Talk Anymore\", 'Change']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ae0bc89b-3040-43d5-842c-9cbfe1280d66",
    "source-id": "1f646594-62c9-4e3d-8bfa-425b684bd207"
   },
   "outputs": [],
   "source": [
    "outfile = open(\"songs.txt\", \"w\")\n",
    "\n",
    "outfile.write('Name,Song')\n",
    "outfile.write('\\n')\n",
    "\n",
    "for name, song in artist_songs.items():\n",
    "    if len(list(song)) > 1:\n",
    "        for itm in song:\n",
    "            row_string = f'{name},{itm}'\n",
    "            outfile.write(row_string)\n",
    "            outfile.write('\\n')\n",
    "    else:\n",
    "        row_string = f'{name},{song}'\n",
    "        outfile.write(row_string)\n",
    "        outfile.write('\\n')\n",
    "    \n",
    "outfile.close()\n",
    "with open(\"songs.txt\", \"r\") as file:\n",
    "    file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db0e9ba0-81ae-4ad0-8666-bc1036335176",
    "source-id": "80d575d9-10a5-4242-a19c-08ec3f1fe898"
   },
   "source": [
    "### Problem 10 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8d5d56b9-15b9-44e8-a75f-4dc6408eba80",
    "source-id": "36a084c4-0b13-4c2d-8d8e-48dda4cc3c09"
   },
   "outputs": [],
   "source": [
    "f = open('songs.txt')\n",
    "data = f.read()\n",
    "f.close()\n",
    "desiredResult = \"\"\"Name,Song\n",
    "Taylor Swift,Love Story\n",
    "Taylor Swift,You need to Calm Down\n",
    "Charlie Puth,Attention\n",
    "Charlie Puth,We Don't Talk Anymore\n",
    "Charlie Puth,Change\"\"\"\n",
    "\n",
    "assert data.strip() == desiredResult.strip(), \"Checking the contents of 'songs.txt'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "264e9f5d-7693-427d-8368-64a7aa915acc",
    "source-id": "c7a3e229-c215-4d3d-a8fd-f2faac9cc8ec"
   },
   "source": [
    "---\n",
    "## Problem 11 (Demonstrate Your Understanding)\n",
    "\n",
    "Write code and/or a Python comment that demonstrates your understanding of the material in this problem set. This assignment requires effort and demonstration of true understanding and will be evaluated carefully (this does not mean it needs to be long, just clear and accurate. In fact, it should be brief; ideally just 2-3 sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7e20fc78-857a-48d9-bce8-c398cc8a3cd1",
    "source-id": "98716310-2cd8-4d91-a8ba-0cbb9479ec52"
   },
   "outputs": [],
   "source": [
    "# Files\n",
    "# Dictionaries\n",
    "# Dictionary Accumulation\n",
    "\n",
    "# I decided to attach a code I used in the \"Sentiment Analysis\" project on UMICH's Python 3 Coursera course, hope that's demonstrative enough:\n",
    "# Sorry, I had no idea how else could I demonstrate it enough\n",
    "\n",
    "# It opens Twitter data file and extracts data, which help us to detect how positive or negative each tweet is\n",
    "# and saves the result into another file \n",
    "# Made a scatterplot from it here https://www.coursera.org/learn/python-functions-files-dictionaries/peer/TBpNR/project-part-2-sentiment-analysis/review/d2c6JHnZEeuV0A6Gj67kZQ\n",
    "\n",
    "project = open(\"project_twitter_data.csv\",\"r\")\n",
    "result = open(\"resulting_data.csv\",\"w\")\n",
    "\n",
    "#---Functions---\n",
    "def strip_punctuation(word):\n",
    "    for achar in word:\n",
    "        if achar in punctuation_chars:\n",
    "            word = word.replace(achar,'')\n",
    "    return word\n",
    "\n",
    "def get_pos(sentence):\n",
    "    count = 0\n",
    "    for word in sentence.split(' '):\n",
    "        word = word.lower()\n",
    "        if strip_punctuation(word) in positive_words:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_neg(sentence):\n",
    "    count = 0\n",
    "    for word in sentence.split(' '):\n",
    "        word = word.lower()\n",
    "        if strip_punctuation(word) in negative_words:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#-------------GIVEN\n",
    "punctuation_chars = [\"'\", '\"', \",\", \".\", \"!\", \":\", \";\", '#', '@']\n",
    "\n",
    "# lists of words to use\n",
    "positive_words = []\n",
    "with open(\"positive_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            positive_words.append(lin.strip())\n",
    "\n",
    "\n",
    "negative_words = []\n",
    "with open(\"negative_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            negative_words.append(lin.strip())\n",
    "#-------------END GIVEN\n",
    "\n",
    "# Write in data file            \n",
    "def write_results(result):\n",
    "    \n",
    "    result.write(\"Number of Retweets, Number of Replies, Positive Score, Negative Score, Net Score\")\n",
    "    result.write(\"\\n\")\n",
    "             \n",
    "    lines_project =  project.readlines()\n",
    "    for line in lines_project[1:]:\n",
    "        list_fin = line.strip().split(',')\n",
    "        result.write(\"{}, {}, {}, {}, {}\".format(list_fin[1], list_fin[2], get_pos(list_fin[0]), get_neg(list_fin[0]), (get_pos(list_fin[0])-get_neg(list_fin[0]))))    \n",
    "        result.write(\"\\n\")\n",
    "            \n",
    "write_results(result)\n",
    "project.close()\n",
    "result.close()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dcdcf2b-0db4-40e7-ab0a-7ea52a2c4f37",
    "source-id": "db0ea945-1b17-4c81-b55b-f26d20e450d6"
   },
   "source": [
    "---\n",
    "## Problem 12 (Look Ahead to Defining Functions)\n",
    "\n",
    "Define a function named `addOne` that accepts one argument (an integer) and returns that argument's value plus `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4f19970f-4abe-482d-b446-b42e0829f8d5",
    "source-id": "309f7849-4325-4b7c-a09c-b8d10ace68a3"
   },
   "outputs": [],
   "source": [
    "def addOne(x: int) -> int:\n",
    "    return x + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72bd269f-fb1f-48d9-b57f-674ad5f58779",
    "source-id": "79db71ff-c0a3-4465-b32a-d9744131ae9b"
   },
   "source": [
    "### Problem 12 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "e4fc22ec-7a7b-449f-b285-d4ef6d1cb13a",
    "source-id": "712f0ea0-3e32-4a1f-aaef-334587197014"
   },
   "outputs": [],
   "source": [
    "assert addOne(5) == 6\n",
    "assert addOne(-1) == 0\n",
    "assert addOne(100) == 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0937c16e-e13a-416d-b9b7-5385e26d3fb0",
    "source-id": "93dcbb56-e627-4c08-9681-9266b90d5024"
   },
   "source": [
    "---\n",
    "## Problem 13 (Look Ahead to Tuple Packing and Unpacking)\n",
    "\n",
    "Using one line of code, assign variables `x` and `y` to `1` and `2` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "998ebdf4-a340-4c72-9a41-24f8fbb5b291",
    "source-id": "9ae08d67-502d-48f8-a998-7cd64ead26a1"
   },
   "outputs": [],
   "source": [
    "x, y = 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cddc0424-1c53-4db5-aebb-6bf85d0b6a47",
    "source-id": "ae74f6b8-4da2-404a-ab5a-4d3ca1b56fce"
   },
   "source": [
    "### Problem 13 Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "c14c59fd-81f4-4d14-8a52-bb23d1510a7c",
    "source-id": "cc908816-28ee-4f79-855d-8320c213901a"
   },
   "outputs": [],
   "source": [
    "assert x == 1\n",
    "assert y == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e307bc62-77ff-4025-ba18-cc0f4c868c57",
    "source-id": "1142eb5f-ff25-4774-a5ba-fe4e6aa6ac4d"
   },
   "source": [
    "---\n",
    "---\n",
    "## Collaborators and Sources of Help\n",
    "In this markdown cell, list names of any people you worked with or got help from, and provide links to or descriptions of any external resources you consulted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d8e221b-ae4c-4389-8b3e-c22300474518",
    "source-id": "2ce2cd73-e65b-4b5c-b382-6901a5afe6d9"
   },
   "source": [
    "- List your collaborators here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6829b370-e92a-4398-a7ee-961facfb5f56",
    "source-id": "aabbaac6-4299-455a-94c7-ee8d46223f68"
   },
   "source": [
    "## Upload your solutions to Canvas\n",
    "\n",
    "Upload your .ipynb file to Canvas.\n",
    "\n",
    "*Note: You may submit any number of times before the deadline*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98fde7af-b86b-4d66-a5e2-62c4be14da4c",
    "source-id": "5904603d-ef23-407e-b7ac-16284b3ccff7"
   },
   "source": [
    "\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMM             MMMMMMMMMMMMMMMMM             MMMMMMMMM\n",
    "    MMMMMMMM              MMMMMMMMMMMMMMM              MMMMMMMMM\n",
    "    MMMMMMMM                MMMMMMMMMMM                MMMMMMMMM\n",
    "    MMMMMMMM                 MMMMMMMMM                 MMMMMMMMM\n",
    "    MMMMMMMM                  MMMMMMM                  MMMMMMMMM\n",
    "    MMMMMMMMMMMM               MMMMM                MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM                MMM                 MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM                 V                  MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM                                    MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM         ^               ^          MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM         MM             MM          MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM         MMMM         MMMM          MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM         MMMMM       MMMMM          MMMMMMMMMMMM\n",
    "    MMMMMMMMMMMM         MMMMMM     MMMMMM          MMMMMMMMMMMM\n",
    "    MMMMMMMM                MMMM   MMMM                MMMMMMMMM\n",
    "    MMMMMMMM                MMMMMVMMMMM                MMMMMMMMM\n",
    "    MMMMMMMM                MMMMMMMMMMM                MMMMMMMMM\n",
    "    MMMMMMMM                MMMMMMMMMMM                MMMMMMMMM\n",
    "    MMMMMMMM                MMMMMMMMMMM                MMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n",
    "    MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM  "
   ]
  }
 ],
 "metadata": {
  "exam_gen_problems": [
   "21b54a7f-a97a-4585-9755-d27857445b64",
   "6ce75932-b28e-4232-9113-4a3e5799ac73",
   "7fce178e-8e16-4171-9ab8-bd4ca2aa3048",
   "479a9fa3-d51c-4319-9bc6-0f66c2069a02",
   "ee206ab0-b256-4a4f-9483-17b8af6ed68b",
   "3628ae71-b735-432a-83a3-ee7d39d0516d",
   "a428380d-ba3a-4c2d-8126-f424b3a9720b",
   "847b4df8-aab4-45f5-b681-f21c380fcc66",
   "f48b61a1-f367-4cee-a4e6-1a5d684ad2d9",
   "ba499b5e-ce2c-4914-98f3-8b4816db9f77",
   "4b1dd19c-52fe-4b47-a8be-933e4513ec7a",
   "c7a3e229-c215-4d3d-a8fd-f2faac9cc8ec",
   "db0ea945-1b17-4c81-b55b-f26d20e450d6",
   "93dcbb56-e627-4c08-9681-9266b90d5024",
   "1142eb5f-ff25-4774-a5ba-fe4e6aa6ac4d"
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
